% Non-CWR
@inproceedings{vectors_collobert2008unified,
  title={A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author={Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={160--167},
  year={2008},
  organization={ACM},
  url={http://www.ronan.collobert.com/pub/matos/2008_nlp_icml.pdf}
}
% uses of non-CWR
@inproceedings{vectors_turian-etal-2010-word,
    title = "Word Representations: A Simple and General Method for Semi-Supervised Learning",
    author = "Turian, Joseph  and
      Ratinov, Lev-Arie  and
      Bengio, Yoshua",
    booktitle = "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    pages = "384--394",
    url = "https://www.aclweb.org/anthology/P10-1040/"
}
@inproceedings{vectors_kim-2014-convolutional,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751",
}
% word sense meaning problem in non-cwr
@article{vectors_camacho2018word,
  title={From word to sense embeddings: A survey on vector representations of meaning},
  author={Camacho-Collados, Jose and Pilehvar, Mohammad Taher},
  journal={Journal of Artificial Intelligence Research},
  volume={63},
  pages={743--788},
  year={2018},
  url={https://jair.org/index.php/jair/article/view/11259/26454}
}
% CWR
@inproceedings{vectors_peters-etal-2017-semi,
    title = "Semi-supervised sequence tagging with bidirectional language models",
    author = "Peters, Matthew  and
      Ammar, Waleed  and
      Bhagavatula, Chandra  and
      Power, Russell",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/P17-1161",
    pages = "1756--1765",
}
@inproceedings{vectors_peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
}
@inproceedings{vectors_liu-etal-2019-linguistic,
    title = "Linguistic Knowledge and Transferability of Contextual Representations",
    author = "Liu, Nelson F.  and
      Gardner, Matt  and
      Belinkov, Yonatan  and
      Peters, Matthew E.  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1112",
    pages = "1073--1094",
}
@techreport{vectors_Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
  url={https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf},
  institution={OpenAI} 
}
@inproceedings{vectors_devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}
@inproceedings{vectors_peters-etal-2018-dissecting,
    title = "Dissecting Contextual Word Embeddings: Architecture and Representation",
    author = "Peters, Matthew  and
      Neumann, Mark  and
      Zettlemoyer, Luke  and
      Yih, Wen-tau",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/D18-1179",
    pages = "1499--1509",
}
@inproceedings{vectors_howard-ruder-2018-universal,
    title = "Universal Language Model Fine-tuning for Text Classification",
    author = "Howard, Jeremy  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/P18-1031",
    pages = "328--339",
}
@article{vectors_tsai2019small,
  title={Small and practical bert models for sequence labeling},
  author={Tsai, Henry and Riesa, Jason and Johnson, Melvin and Arivazhagan, Naveen and Li, Xin and Archer, Amelia},
  journal={arXiv preprint arXiv:1909.00100},
  year={2019},
  url={https://arxiv.org/pdf/1909.00100.pdf}
}
@article{vectors_liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019},
  url={https://arxiv.org/pdf/1907.11692.pdf}
}
@inproceedings{vectors_liu-etal-2019-multi,
    title = "Multi-Task Deep Neural Networks for Natural Language Understanding",
    author = "Liu, Xiaodong  and
      He, Pengcheng  and
      Chen, Weizhu  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/P19-1441",
    pages = "4487--4496",
}
@article{vectors_lample2019cross,
  title={Cross-lingual Language Model Pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291},
  year={2019},
  url={https://arxiv.org/pdf/1901.07291.pdf}
}

